import soundfile as sf
import scipy.signal
import sox
import random
import os
import warnings
import jams
from collections import namedtuple
import logging
import tempfile
import numpy as np
import shutil
import pandas as pd
from .ambiscaper_exceptions import AmbiScaperError
from .ambiscaper_warnings import AmbiScaperWarning
from .util import _close_temp_files, spherical_to_cartesian, _validate_distribution, SUPPORTED_DIST, _get_event_idx_from_id, _generate_event_id_from_idx
from .util import _set_temp_logging_level
from .util import _get_sorted_files
from .util import _validate_folder_path
from .util import _populate_label_list
from .util import max_polyphony
from .util import polyphony_gini
from .util import is_real_number, is_real_array
from .audio import get_integrated_lufs
from .ambisonics import get_number_of_ambisonics_channels, change_channel_ordering_fuma_2_acn, change_normalization_fuma_2_sn3d
from .ambisonics import _validate_ambisonics_order
from .ambisonics import _validate_ambisonics_spread_slope
from .ambisonics import get_ambisonics_spread_coefs
from .ambisonics import get_ambisonics_coefs
from .reverb_ambisonics import generate_RIR_path, _validate_smir_reverb_spec, SMIR_SUPPORTED_VIRTUAL_MICS, SMIR_SOUND_SPEED, SMIR_NUM_HARMONICS, SMIR_OVERSAMPLING_FACTOR, get_receiver_position, SMIR_DEFAULT_SOURCE_RADIUS, SMIR_HIGH_PASS_FILTER, SMIR_REFLECTION_ORDER, SMIR_REFLECTION_COEF_ANGLE_DEPENDENCY, _validate_s3a_reverb_spec, retrieve_available_recorded_IRs
from .reverb_ambisonics import retrieve_RIR_positions
from .reverb_ambisonics import MATLAB_ROOT
from .reverb_ambisonics import S3A_FILTER_NAME
from .reverb_ambisonics import S3A_FILTER_EXTENSION
from .reverb_ambisonics import SMIR_FOLDER_PATH
from .reverb_ambisonics import S3aReverbSpec
from .reverb_ambisonics import SmirReverbSpec
from .reverb_ambisonics import get_max_ambi_order_from_reverb_config
import matlab_wrapper



# Define single event spec as namedtuple
EventSpec = namedtuple(
    'EventSpec',
    ['source_file', 'event_id',
     'source_time', 'event_time', 'event_duration',
     'event_azimuth', 'event_elevation', 'event_spread',
     'snr', 'role', 'pitch_shift', 'time_stretch'], verbose=False)
'''
Container for storing event specifications, either probabilistic (i.e. using
distribution tuples to specify possible values) or instantiated (i.e. storing
constants directly).
'''


def generate_from_jams(jams_infile, audio_outfile, fg_path=None, bg_path=None,
                       jams_outfile=None):
    '''
    Generate a soundscape based on an existing ambiscaper JAMS file and save to
    disk.

    Args:
        jams_infile : str
            Path to JAMS file (must be a file previously generated by AmbiScaper).
        audio_outfile : str
            Path for saving the generated soundscape audio.
        fg_path : str or None
            Specifies a different path for foreground audio than the one stored in
            the input jams file. For the reconstruction to be successful the folder
            and file structure inside this path must be identical the one that was
            used to create the input jams file. If None (default), the fg_path from
            the input jams file will be used.
        bg_path : str or None
            Specifies a different path for background audio than the one stored in
            the input jams file. For the reconstruction to be successful the folder
            and file structure inside this path must be identical the one that was
            used to create the input jams file. If None (default), the bg_path from
            the input jams file will be used.
        jams_outfile : str or None
            Path for saving new JAMS file, if None (default) a new JAMS is not
            saved. Useful when either fg_path or bg_path is not None, as it saves
            a new JAMS files where the source file paths match the new fg_path
            and/or bg_path.

    Raises:
        AmbiScaperError
            If jams_infile does not point to a valid JAMS file that was previously
            generated by AmbiScaper and contains an annotation of the sound_event
            namespace.

    '''
    jam = jams.load(jams_infile)
    anns = jam.search(namespace='ambiscaper_sound_event')

    if len(anns) == 0:
        raise AmbiScaperError(
            'JAMS file does not contain any annotation with namespace '
            'sound_event.')

    ann = anns[0]

    # Update paths
    if fg_path is None:
        new_fg_path = ann.sandbox.ambiscaper['fg_path']
    else:
        new_fg_path = os.path.expanduser(fg_path)
        # Update source files
        for idx in ann.data.index:
            if ann.data.loc[idx, 'value']['role'] == 'foreground':
                sourcefile = ann.data.loc[idx, 'value']['source_file']
                sourcefilename = os.path.basename(sourcefile)
                parent = os.path.dirname(sourcefile)
                parentname = os.path.basename(parent)
                newsourcefile = os.path.join(
                    new_fg_path, parentname, sourcefilename)
                ann.data.loc[idx, 'value']['source_file'] = newsourcefile
        # Update sandbox
        ann.sandbox.ambiscaper['fg_path'] = new_fg_path

    if bg_path is None:
        new_bg_path = ann.sandbox.ambiscaper['bg_path']
    else:
        new_bg_path = os.path.expanduser(bg_path)
        # Update source files
        for idx in ann.data.index:
            if ann.data.loc[idx, 'value']['role'] == 'background':
                sourcefile = ann.data.loc[idx, 'value']['source_file']
                sourcefilename = os.path.basename(sourcefile)
                parent = os.path.dirname(sourcefile)
                parentname = os.path.basename(parent)
                newsourcefile = os.path.join(
                    new_bg_path, parentname, sourcefilename)
                ann.data.loc[idx, 'value']['source_file'] = newsourcefile
        # Update sandbox
        ann.sandbox.ambiscaper['bg_path'] = new_bg_path

    # Create ambiscaper object
    duration = ann.sandbox.ambiscaper['duration']
    ambisonics_order = ann.sandbox.ambiscaper['ambisonics_order']
    tau = ann.sandbox.ambiscaper['ambisonics_spread_slope']
    sc = AmbiScaper(duration,
                ambisonics_order,
                tau,
                new_fg_path,
                new_bg_path)

    # Set synthesis parameters
    sc.ref_db = ann.sandbox.ambiscaper['ref_db']
    sc.n_channels = get_number_of_ambisonics_channels(ambisonics_order)
    sc.fade_in_len = ann.sandbox.ambiscaper['fade_in_len']
    sc.fade_out_len = ann.sandbox.ambiscaper['fade_out_len']

    # Generate audio and save to disk
    reverb = ann.sandbox.ambiscaper['reverb']
    sc._generate_audio(audio_outfile, ann, reverb=reverb,
                       disable_sox_warnings=True)

    # If there are slice (trim) operations, need to perform them!
    if 'slice' in ann.sandbox.keys():
        for sliceop in ann.sandbox['slice']:
            # must use temp file in order to save to same file
            tmpfiles = []
            with _close_temp_files(tmpfiles):
                # Create tmp file
                tmpfiles.append(
                    tempfile.NamedTemporaryFile(suffix='.wav', delete=False))
                # Save trimmed result to temp file
                tfm = sox.Transformer()
                tfm.trim(sliceop['slice_start'], sliceop['slice_end'])
                tfm.build(audio_outfile, tmpfiles[-1].name)
                # Copy result back to original file
                shutil.copyfile(tmpfiles[-1].name, audio_outfile)

    # Optionally save new jams file
    if jams_outfile is not None:
        jam.save(jams_outfile)


def trim(audio_infile, jams_infile, audio_outfile, jams_outfile, start_time,
         end_time, no_audio=False):
    '''
    Trim and audio file and corresponding AmbiScaper JAMS file and save to disk.

    Given an input audio file and corresponding jams file, trim both the audio
    and all annotations in the jams file to the time range ``[start_time,
    end_time]`` and save the result to ``audio_outfile`` and ``jams_outfile``
    respectively. This function uses ``jams.slice()`` for trimming the jams
    file while ensuring the start times of the jam's annotations and
    observations they contain match the trimmed audio file.

    Args:
        audio_infile : str
            Path to input audio file
        jams_infile : str
            Path to input jams file
        audio_outfile : str
            Path to output trimmed audio file
        jams_outfile : str
            Path to output trimmed jams file
        start_time : float
            Start time for trimmed audio/jams
        end_time : float
            End time for trimmed audio/jams
        no_audio : bool
            If true, operates on the jams only. Audio input and output paths
            don't have to point to valid files.
    '''

    # First trim jams (might raise an error)
    jam = jams.load(jams_infile)
    jam_sliced = jam.slice(start_time, end_time, strict=False)

    # Special work for annotations of the ambiscaper 'sound_event' namespace
    for ann in jam_sliced.annotations:
        if ann.namespace == 'ambiscaper_sound_event':

            # DON'T MODIFY event's value dict! Keeps original instantiated
            # values for reconstruction / reproducibility.
            # Count number of FG events
            n_events = 0
            for idx, line in ann.data.iterrows():
                if line.value['role'] == 'foreground':
                    n_events += 1

            # Re-compute max polyphony
            poly = max_polyphony(ann)

            # Re-compute polyphony gini
            gini = polyphony_gini(ann)

            # Update specs in sandbox
            ann.sandbox.ambiscaper['n_events'] = n_events
            ann.sandbox.ambiscaper['polyphony_max'] = poly
            ann.sandbox.ambiscaper['polyphony_gini'] = gini
            ann.sandbox.ambiscaper['duration'] = ann.duration

    # Save result to output jams file
    jam_sliced.save(jams_outfile)

    # Next, trim audio
    if not no_audio:
        tfm = sox.Transformer()
        tfm.trim(start_time, end_time)
        if audio_outfile != audio_infile:
            tfm.build(audio_infile, audio_outfile)
        else:
            # must use temp file in order to save to same file
            tmpfiles = []
            with _close_temp_files(tmpfiles):
                # Create tmp file
                tmpfiles.append(
                    tempfile.NamedTemporaryFile(
                        suffix='.wav', delete=False))
                # Save trimmed result to temp file
                tfm.build(audio_infile, tmpfiles[-1].name)
                # Copy result back to original file
                shutil.copyfile(tmpfiles[-1].name, audio_outfile)




def _get_value_from_dist(dist_tuple):
    '''
    Sample a value from the provided distribution tuple.

    Given a distribution tuple, validate its format/values and then sample
    and return a single value from the distribution specified by the tuple.

    Parameters
    ----------
    dist_tuple : tuple
        Distribution tuple to be validated. See ``AmbiScaper.add_event`` for
        details about the expected format for the distribution tuple.

    Returns
    -------
    value
        A value from the specified distribution.

    See Also
    --------
    AmbiScaper.add_event :  Add a foreground sound event to the foreground
    specification.
    _validate_distribution : Check whether a tuple specifying a parameter
    distribution has a valid format, if not raise an error.

    '''
    # Make sure it's a valid distribution tuple
    _validate_distribution(dist_tuple)
    return SUPPORTED_DIST[dist_tuple[0]](*dist_tuple[1:])



def _validate_source_file(source_file_tuple):
    '''
    Validate that a source_file tuple is in the right format a that it's values
    are valid.

    Parameters
    ----------
    source_file : tuple
        Source file tuple (see ```AmbiScaper.add_event``` for required format).

    Raises
    ------
    AmbiScaperError
        If the validation fails.

    '''
    # Make sure it's a valid distribution tuple
    _validate_distribution(source_file_tuple)

    # If source file is specified explicitly
    if source_file_tuple[0] == "const":
        # 1. the filepath must point to an existing file
        if not os.path.isfile(source_file_tuple[1]):
            raise AmbiScaperError(
                "Source file not found: {:s}".format(source_file_tuple[1]))
    # Otherwise it must be specified using "choose"
    elif source_file_tuple[0] == "choose":
        if source_file_tuple[1]:  # list is not empty
            if not all(os.path.isfile(x) for x in source_file_tuple[1]):
                raise AmbiScaperError(
                    'Source file list must either be empty or all paths in '
                    'the list must point to valid files.')
    else:
        raise AmbiScaperError(
            'Source file must be specified using a "const" or "choose" tuple.')



def _validate_time(time_tuple):
    '''
    Validate that a time tuple has the right format and that the
    specified distribution cannot result in a negative time.

    Parameters
    ----------
    time_tuple : tuple
        Time tuple (see ```AmbiScaper.add_event``` for required format).

    Raises
    ------
    AmbiScaperError
        If the validation fails.

    '''
    # Make sure it's a valid distribution tuple
    _validate_distribution(time_tuple)

    # Ensure the values are valid for time
    if time_tuple[0] == "const":
        if (time_tuple[1] is None or
                not is_real_number(time_tuple[1]) or
                    time_tuple[1] < 0):
            raise AmbiScaperError(
                'Time must be a real non-negative number.')
    elif time_tuple[0] == "choose":
        if (not time_tuple[1] or
                not is_real_array(time_tuple[1]) or
                not all(x is not None for x in time_tuple[1]) or
                not all(x >= 0 for x in time_tuple[1])):
            raise AmbiScaperError(
                'Time list must be a non-empty list of non-negative real '
                'numbers.')
    elif time_tuple[0] == "uniform":
        if time_tuple[1] < 0:
            raise AmbiScaperError(
                'A "uniform" distribution tuple for time must have '
                'min_value >= 0')
    elif time_tuple[0] == "normal":
        warnings.warn(
            'A "normal" distribution tuple for time can result in '
            'negative values, in which case the distribution will be '
            're-sampled until a positive value is returned: this can result '
            'in an infinite loop!',
            AmbiScaperWarning)
    elif time_tuple[0] == "truncnorm":
        if time_tuple[3] < 0:
            raise AmbiScaperError(
                'A "truncnorm" distirbution tuple for time must specify a non-'
                'negative trunc_min value.')


def _validate_duration(duration_tuple):
    '''
    Validate that a duration tuple has the right format and that the
    specified distribution cannot result in a negative or zero value.

    Parameters
    ----------
    duration : tuple
        Duration tuple (see ```AmbiScaper.add_event``` for required format).

    Raises
    ------
    AmbiScaperError
        If the validation fails.

    '''
    # Make sure it's a valid distribution tuple
    _validate_distribution(duration_tuple)

    # Ensure the values are valid for duration
    if duration_tuple[0] == "const":
        if (not is_real_number(duration_tuple[1]) or
                    duration_tuple[1] <= 0):
            raise AmbiScaperError(
                'Duration must be a real number greater than zero.')
    elif duration_tuple[0] == "choose":
        if (not duration_tuple[1] or
                not is_real_array(duration_tuple[1]) or
                not all(x > 0 for x in duration_tuple[1])):
            raise AmbiScaperError(
                'Duration list must be a non-empty list of positive real '
                'numbers.')
    elif duration_tuple[0] == "uniform":
        if duration_tuple[1] <= 0:
            raise AmbiScaperError(
                'A "uniform" distribution tuple for duration must have '
                'min_value > 0')
    elif duration_tuple[0] == "normal":
        warnings.warn(
            'A "normal" distribution tuple for duration can result in '
            'non-positives values, in which case the distribution will be '
            're-sampled until a positive value is returned: this can result '
            'in an infinite loop!',
            AmbiScaperWarning)
    elif duration_tuple[0] == "truncnorm":
        if duration_tuple[3] <= 0:
            raise AmbiScaperError(
                'A "truncnorm" distirbution tuple for time must specify a '
                'positive trunc_min value.')


def _validate_azimuth(azimuth_tuple):
    '''
    Validate that an azimuth tuple has the right format and that the
    specified distribution wraps into (0..2pi)

    Parameters
    ----------
    azimuth : tuple
        Azimuth tuple (see ```AmbiScaper.add_event``` for required format).

    Raises
    ------
    AmbiScaperError
        If the validation fails.

    '''
    # Make sure it's a valid distribution tuple
    _validate_distribution(azimuth_tuple)

    # Ensure the values are valid for duration
    if azimuth_tuple[0] == "const":
        if (not is_real_number(azimuth_tuple[1]) or azimuth_tuple[1] < 0 or azimuth_tuple[1] > 2 * np.pi):
            raise AmbiScaperError(
                'Azimuth must be a real number in the range [0..2pi].')
    elif azimuth_tuple[0] == "choose":
        if (not azimuth_tuple[1] or
                not is_real_array(azimuth_tuple[1]) or
                not all(x >= 0 for x in azimuth_tuple[1]) or
                not all(x <= (2 * np.pi) for x in azimuth_tuple[1])):
            raise AmbiScaperError(
                'Azimuth list must be a non-empty list of real '
                'numbers in the range [0..2pi].')
    elif azimuth_tuple[0] == "uniform":
        if azimuth_tuple[1] < 0:
            raise AmbiScaperError(
                'A "uniform" distribution tuple for azimuth must have '
                'min_value >= 0')
        elif azimuth_tuple[2] > (2 * np.pi):
            raise AmbiScaperError(
                'A "uniform" distribution tuple for azimuth must have '
                'max_value <= 2pi')
    elif azimuth_tuple[0] == "normal":
        warnings.warn(
            'A "normal" distribution tuple for azimuth can result in '
            'values out of range, in which case the distribution will be '
            're-sampled until a positive value is returned: this can result '
            'in an infinite loop!',
            AmbiScaperWarning)
    elif azimuth_tuple[0] == "truncnorm":
        if azimuth_tuple[3] < 0:
            raise AmbiScaperError(
                'A "truncnorm" distirbution tuple for azimuth must specify a '
                'trunc_min >= 0.')
        elif azimuth_tuple[4] > (2 * np.pi):
            raise AmbiScaperError(
                'A "truncnorm" distirbution tuple for azimuth must specify a '
                'trunc_max value <= 2pi.')


def _validate_elevation(elevation_tuple):
    '''
    Validate that an azimuth tuple has the right format and that the
    specified distribution wraps into (-pi/2..pi/2)

    Parameters
    ----------
    duration : tuple
        Duration tuple (see ```AmbiScaper.add_event``` for required format).

    Raises
    ------
    AmbiScaperError
        If the validation fails.

    '''
    # Make sure it's a valid distribution tuple
    _validate_distribution(elevation_tuple)

    # Ensure the values are valid for duration
    if elevation_tuple[0] == "const":
        if (not is_real_number(elevation_tuple[1]) or elevation_tuple[1] < -np.pi / 2. or elevation_tuple[
            1] > np.pi / 2.):
            raise AmbiScaperError(
                'Elevation must be a real number in the range [-pi/2..pi/2].')
    elif elevation_tuple[0] == "choose":
        if (not elevation_tuple[1] or
                not is_real_array(elevation_tuple[1]) or
                not all(x >= -np.pi / 2. for x in elevation_tuple[1]) or
                not all(x <= np.pi / 2. for x in elevation_tuple[1])):
            raise AmbiScaperError(
                'Elevation list must be a non-empty list of real '
                'numbers in the range [-pi/2..pi/2]')
    elif elevation_tuple[0] == "uniform":
        if elevation_tuple[1] < -np.pi / 2.:
            raise AmbiScaperError(
                'A "uniform" distribution tuple for elevation must have '
                'min_value >= -pi/2')
        elif elevation_tuple[2] > np.pi / 2.:
            raise AmbiScaperError(
                'A "uniform" distribution tuple for elevation must have '
                'max_value <= pi/2')
    elif elevation_tuple[0] == "normal":
        warnings.warn(
            'A "normal" distribution tuple for elevation can result in '
            'values out of range, in which case the distribution will be '
            're-sampled until a positive value is returned: this can result '
            'in an infinite loop!',
            AmbiScaperWarning)
    elif elevation_tuple[0] == "truncnorm":
        if elevation_tuple[3] < -np.pi / 2.:
            raise AmbiScaperError(
                'A "truncnorm" distirbution tuple for elevation must specify a '
                'trunc_min >= -pi/2')
        elif elevation_tuple[4] > np.pi / 2.:
            raise AmbiScaperError(
                'A "truncnorm" distirbution tuple for elevation must specify a '
                'trunc_max value <= pi/2')


def _validate_spread(spread_tuple):
    '''
        Validate that a spread tuple has the right format and that the
        specified distribution wraps into [0,1]

        Parameters
        ----------
        duration : tuple
            Duration tuple (see ```AmbiScaper.add_event``` for required format).

        Raises
        ------
        AmbiScaperError
            If the validation fails.

        '''
    # Make sure it's a valid distribution tuple
    _validate_distribution(spread_tuple)

    # Ensure the values are valid for duration
    if spread_tuple[0] == "const":
        if (not is_real_number(spread_tuple[1]) or spread_tuple[1] < 0 or spread_tuple[1] > 1):
            raise AmbiScaperError(
                'Spread must be a real number in the range [0,1].')
    elif spread_tuple[0] == "choose":
        if (not spread_tuple[1] or
                not is_real_array(spread_tuple[1]) or
                not all(x >= 0. for x in spread_tuple[1]) or
                not all(x <= 1 for x in spread_tuple[1])):
            raise AmbiScaperError(
                'Spread list must be a non-empty list of real '
                'numbers in the range [0,1]')
    elif spread_tuple[0] == "uniform":
        if spread_tuple[1] < 0:
            raise AmbiScaperError(
                'A "uniform" distribution tuple for spread must have '
                'min_value >= 0')
        elif spread_tuple[2] > 1:
            raise AmbiScaperError(
                'A "uniform" distribution tuple for spread must have '
                'max_value <= 1')
    elif spread_tuple[0] == "normal":
        warnings.warn(
            'A "normal" distribution tuple for spread can result in '
            'values out of range, in which case the distribution will be '
            're-sampled until a positive value is returned: this can result '
            'in an infinite loop!',
            AmbiScaperWarning)
    elif spread_tuple[0] == "truncnorm":
        if spread_tuple[3] < 0:
            raise AmbiScaperError(
                'A "truncnorm" distirbution tuple for spread must specify a '
                'trunc_min >= 0')
        elif spread_tuple[4] > 1:
            raise AmbiScaperError(
                'A "truncnorm" distirbution tuple for spread must specify a '
                'trunc_max value <= 1')


def _validate_snr(snr_tuple):
    '''
    Validate that an snr distribution tuple has the right format.

    Parameters
    ----------
    snr : tuple
        SNR tuple (see ```AmbiScaper.add_event``` for required format).

    Raises
    ------
    AmbiScaperError
        If the validation fails.

    '''
    # Make sure it's a valid distribution tuple
    _validate_distribution(snr_tuple)

    # Ensure the values are valid for SNR
    if snr_tuple[0] == "const":
        if not is_real_number(snr_tuple[1]):
            raise AmbiScaperError(
                'SNR must be a real number.')
    elif snr_tuple[0] == "choose":
        if (not snr_tuple[1] or
                not is_real_array(snr_tuple[1])):
            raise AmbiScaperError(
                'SNR list must be a non-empty list of real numbers.')

            # No need to check for "uniform" and "normal" since they must produce a
            # real number and technically speaking any real number is a valid SNR.
            # TODO: do we want to impose limits on the possible SNR values?


def _validate_pitch_shift(pitch_shift_tuple):
    '''
    Validate that a pitch_shift distribution tuple has the right format.

    Parameters
    ----------
    pitch_shift_tuple : tuple
        Pitch shift tuple (see ```AmbiScaper.add_event``` for required format).

    Raises
    ------
    AmbiScaperError
        If the validation fails.

    '''
    # If the tuple is none then it's valid
    if pitch_shift_tuple is not None:
        # Make sure it's a valid distribution tuple
        _validate_distribution(pitch_shift_tuple)

        # Ensure the values are valid for pitch shift
        if pitch_shift_tuple[0] == "const":
            if not is_real_number(pitch_shift_tuple[1]):
                raise AmbiScaperError(
                    'Pitch shift must be a real number.')
        elif pitch_shift_tuple[0] == "choose":
            if (not pitch_shift_tuple[1] or
                    not is_real_array(pitch_shift_tuple[1])):
                raise AmbiScaperError(
                    'Pitch shift list must be a non-empty list of real '
                    'numbers.')

                # No need to check for "uniform" and "normal" since they must produce a
                # real number and technically speaking any real number is a valid pitch
                # shift
                # TODO: do we want to impose limits on the possible pitch shift values?


def _validate_time_stretch(time_stretch_tuple):
    '''
    Validate that a time_stretch distribution tuple has the right format.

    Parameters
    ----------
    time_stretch_tuple: tuple
        Time stretch tuple (see ```AmbiScaper.add_event``` for required format).

    Raises
    ------
    AmbiScaperError
        If the validation fails.

    '''
    # if the tuple is none then its valid
    if time_stretch_tuple is not None:
        # Make sure it's a valid distribution tuple
        _validate_distribution(time_stretch_tuple)

        # Ensure the values are valid for time stretch
        if time_stretch_tuple[0] == "const":
            if (not is_real_number(time_stretch_tuple[1]) or
                        time_stretch_tuple[1] <= 0):
                raise AmbiScaperError(
                    'Time stretch must be a real number greater than zero.')
        elif time_stretch_tuple[0] == "choose":
            if (not time_stretch_tuple[1] or
                    not is_real_array(time_stretch_tuple[1]) or
                    not all(x > 0 for x in time_stretch_tuple[1])):
                raise AmbiScaperError(
                    'Time stretch list must be a non-empty list of positive '
                    'real numbers.')
        elif time_stretch_tuple[0] == "uniform":
            if time_stretch_tuple[1] <= 0:
                raise AmbiScaperError(
                    'A "uniform" distribution tuple for time stretch must have '
                    'min_value > 0')
        elif time_stretch_tuple[0] == "normal":
            warnings.warn(
                'A "normal" distribution tuple for time stretch can result in '
                'non-positives values, in which case the distribution will be '
                're-sampled until a positive value is returned: this can '
                'result in an infinite loop!',
                AmbiScaperWarning)
        elif time_stretch_tuple[0] == "truncnorm":
            if time_stretch_tuple[3] <= 0:
                raise AmbiScaperError(
                    'A "truncnorm" distirbution tuple for time stretch must '
                    'specify a positive trunc_min value.')

                # TODO: do we want to impose limits on the possible time stretch
                # values?


def _validate_event(source_file,
                    source_time, event_time, event_duration,
                    event_azimuth, event_elevation, event_spread,
                    snr, pitch_shift, time_stretch):
    '''
    Check that event parameter values are valid.

    Parameters
    ----------
    source_file : tuple
    source_time : tuple
    event_time : tuple
    event_duration : tuple
    event_azimuth : tuple
    event_elevation : tuple
    event_spread : tuple
    snr : tuple
    pitch_shift : tuple or None
    time_stretch: tuple or None

    Raises
    ------
    AmbiScaperError :
        If any of the input parameters has an invalid format or value.

    See Also
    --------
    AmbiScaper.add_event : Add a foreground sound event to the foreground
    specification.
    '''


    # SOURCE FILE
    _validate_source_file(source_file)

    # SOURCE TIME
    _validate_time(source_time)

    # EVENT TIME
    _validate_time(event_time)

    # EVENT DURATION
    _validate_duration(event_duration)

    # EVENT AZIMUTH
    _validate_azimuth(event_azimuth)

    # EVENT ELEVATION
    _validate_elevation(event_elevation)

    # EVENT SPREAD
    _validate_spread(event_spread)

    # SNR
    _validate_snr(snr)

    # Pitch shift
    _validate_pitch_shift(pitch_shift)

    # Time stretch
    _validate_time_stretch(time_stretch)


def _validate_soundscape_duration(duration):
    # TODO comments

    # Duration must be a positive real number
    if not is_real_number(duration):
        raise AmbiScaperError('Duration must be a real value')
    elif duration <= 0:
        raise AmbiScaperError('Duration must be a positive value')



class AmbiScaper(object):

    def __init__(self,
                 duration,
                 ambisonics_order,
                 ambisonics_spread_slope,
                 fg_path,
                 bg_path):
        '''
        Create am AmbiScaper object.

        Parameters
        ----------
        duration : float
            Duration of the soundscape, in seconds.
        ambisonics_order: int
            Ambisonics Order
        ambisonics_spread_slope: float
            TODO
        # TODO: num channels, but also all sr, ref_db etc... parameters??
        fg_path : str
            Path to foreground folder.
        bg_path : str
            Path to background folder.

        '''
        # Validate soundscape duration
        _validate_soundscape_duration(duration)
        self.duration = duration

        # Validate ambisonics order
        _validate_ambisonics_order(ambisonics_order)
        self.ambisonics_order = ambisonics_order
        self.num_channels = get_number_of_ambisonics_channels(ambisonics_order)

        # Validate ambisonics spread slope
        _validate_ambisonics_spread_slope(ambisonics_spread_slope)
        self.ambisonics_spread_slope = ambisonics_spread_slope

        # Initialize parameters
        self.sr = 48000
        self.ref_db = -12
        self.fade_in_len = 0.01  # 10 ms
        self.fade_out_len = 0.01  # 10 ms

        # Start with empty specifications
        self.fg_spec = []
        self.bg_spec = []

        # Validate paths and set
        expanded_fg_path = os.path.expanduser(fg_path)
        expanded_bg_path = os.path.expanduser(bg_path)
        _validate_folder_path(expanded_fg_path)
        _validate_folder_path(expanded_bg_path)
        self.fg_path = expanded_fg_path
        self.bg_path = expanded_bg_path

        # Configure reverb to None by default
        self.reverb_spec = None

    def add_background(self, source_file, source_time):
        '''
        Add a background recording to the background specification.

        The background duration will be equal to the duration of the
        soundscape ``AmbiScaper.duration`` specified when initializing the AmbiScaper
        object. If the source file is shorter than this duration then it will
        be concatenated to itself as many times as necessary to produce the
        specified duration when calling ``AmbiScaper.generate``.

        Parameters
        ----------
        source_file : tuple
            Specifies the audio file to use as the source. See Notes below for
            the expected format of this tuple and the allowed values.
        source_time : tuple
            Specifies the desired start time in the source file. See Notes
            below for the expected format of this tuple and the allowed values.
            NOTE: the source time specified by this tuple should be equal to or
            smaller than ``<source file duration> - <soundscape duration>``.
            Larger values will be automatically changed to fulfill this
            requirement when calling ``AmbiScaper.generate``.

        Notes
        -----
        Each parameter of this function is set by passing a distribution
        tuple, whose first item is always the distribution name and subsequent
        items are distribution specific. The supported distribution tuples are:

        * ``("const", value)`` : a constant, given by ``value``.
        * ``("choose", valuelist)`` : choose a value from
          ``valuelist`` at random (uniformly). The
          ``source_file`` parameter also support providing an empty
          ``valuelist`` i.e. ``("choose", [])``, in which case the
          value will be chosen at random from all available files
          as determined automatically by AmbiScaper by examining the file
          structure of ``bg_path`` provided during initialization.
        * ``("uniform", min_value, max_value)`` : sample a random
          value from a uniform distribution between ``min_value``
          and ``max_value``.
        * ``("normal", mean, stddev)`` : sample a random value from a
          normal distribution defined by its mean ``mean`` and
          standard deviation ``stddev``.

        IMPORTANT: not all parameters support all distribution tuples. In
        particular, ``source_file`` only support ``"const"`` and
        ``"choose"``, whereas ``source_time`` supports all distribution tuples.
        As noted above, only ``source_file`` support providing an
        empty ``valuelist`` with ``"choose"``.
        '''

        # These values are fixed for the background sound
        event_time = ("const", 0)
        event_duration = ("const", self.duration)
        event_azimuth = ("const", 0)
        event_elevation = ("const", 0)
        event_spread = ("const", 0)
        snr = ("const", 0)
        role = 'background'
        pitch_shift = None
        time_stretch = None

        # Validate parameter format and values
        _validate_event(source_file,
                        source_time, event_time, event_duration,
                        event_azimuth, event_elevation, event_spread,
                        snr, None, None)

        # Create background sound event
        bg_event = EventSpec(source_file=source_file,
                             source_time=source_time,
                             event_time=event_time,
                             event_duration=event_duration,
                             event_azimuth=event_azimuth,
                             event_elevation=event_elevation,
                             event_spread=event_spread,
                             snr=snr,
                             role=role,
                             event_id=None,  # does not matter now, only on instanciated values
                             pitch_shift=pitch_shift,
                             time_stretch=time_stretch)

        # Add event to background spec
        self.bg_spec.append(bg_event)

    def add_event(self, source_file,
                  source_time, event_time, event_duration,
                  event_azimuth, event_elevation, event_spread,
                  snr, pitch_shift, time_stretch):
        '''
        Add a foreground sound event to the foreground specification.

        Parameters
        ----------
        source_file : tuple
            Specifies the audio file to use as the source. See Notes below for
            the expected format of this tuple and the allowed values.
        source_time : tuple
            Specifies the desired start time in the source file. See Notes
            below for the expected format of this tuple and the allowed values.
            NOTE: the source time specified by this tuple should be equal to or
            smaller than ``<source file duration> - event_duration``. Larger
            values will be automatically changed to fulfill this requirement
            when calling ``AmbiScaper.generate``.
        event_time : tuple
            Specifies the desired start time of the event in the soundscape.
            See Notes below for the expected format of this tuple and the
            allowed values.
            NOTE: The value specified by this tuple should be equal to or
            smaller than ``<soundscapes duration> - event_duration``, and
            larger values will be automatically changed to fulfill this
            requirement when calling ``AmbiScaper.generate``.
        event_duration : tuple
            Specifies the desired duration of the event. See Notes below for
            the expected format of this tuple and the allowed values.
            NOTE: The value specified by this tuple should be equal to or
            smaller than the source file's duration, and larger values will be
            automatically changed to fulfill this requirement when calling
            ``AmbiScaper.generate``.
        event_azimuth : tuple
            Specifies the horizontal angular position of the event. See Notes below for
            the expected format of this tuple and the allowed values.
        event_elevation : tuple
            Specifies the vertical angular position of the event. See Notes below for
            the expected format of this tuple and the allowed values.
        event_spread : tuple
            Specifies the apparent sound source width. See Notes below for
            the expected format of this tuple and the allowed values.
        snr : tuple
            Specifies the desired signal to noise ratio (SNR) between the event
            and the background. See Notes below for the expected format of
            this tuple and the allowed values.
        pitch_shift : tuple
            Specifies the number of semitones to shift the event by. None means
            no pitch shift.
        time_stretch: tuple
            Specifies the time stretch factor (value>1 will make it slower and
            longer, value<1 will makes it faster and shorter).

        Notes
        -----
        Each parameter of this function is set by passing a distribution
        tuple, whose first item is always the distribution name and subsequent
        items are distribution specific. The supported distribution tuples are:

        * ``("const", value)`` : a constant, given by ``value``.
        * ``("choose", valuelist)`` : choose a value from
          ``valuelist`` at random (uniformly). The
          ``source_file`` parameter also support providing an empty
          ``valuelist`` i.e. ``("choose", [])``, in which case the
          value will be chosen at random from all available
          source files as determined automatically by AmbiScaper by examining
          the file structure of ``fg_path`` provided during
          initialization.
        * ``("uniform", min_value, max_value)`` : sample a random
          value from a uniform distribution between ``min_value``
          and ``max_value`` (including ``max_value``).
        * ``("normal", mean, stddev)`` : sample a random value from a
          normal distribution defined by its mean ``mean`` and
          standard deviation ``stddev``.

        IMPORTANT: not all parameters support all distribution tuples. In
        particular, ``source_file`` only support ``"const"`` and
        ``"choose"``, whereas the remaining parameters support all distribution
        tuples. As noted above, only ``source_file`` support
        providing an empty ``valuelist`` with ``"choose"``.

        See Also
        --------
        _validate_event : Check that event parameter values are valid.

        AmbiScaper.generate : Generate a soundscape based on the current
            specification and save to disk as both an audio file and a JAMS file
            describing the soundscape.

        '''

        # Create event
        event = EventSpec(source_file=source_file,
                          source_time=source_time,
                          event_time=event_time,
                          event_duration=event_duration,
                          event_azimuth=event_azimuth,
                          event_elevation=event_elevation,
                          event_spread=event_spread,
                          snr=snr,
                          role='foreground',
                          event_id = None, # does not matter now, only on instanciated values
                          pitch_shift=pitch_shift,
                          time_stretch=time_stretch)

        # Add event to foreground specification
        self.fg_spec.append(event)


    def add_simulated_reverb(self, IRlength, room_dimensions,
                  t60, source_type, microphone_type, reflectivity=None):
        '''
        TODO
        :param IRlength:
        :param room_dimentions:
        :param beta:
        :param source_type:
        :param microphone_type:
        :return:
        '''

        # SAFETY_CHECKS
        _validate_smir_reverb_spec(IRlength, room_dimensions,
                  t60, reflectivity, source_type, microphone_type)

        # Create reverb spec
        if t60 is not None:
            reverb = SmirReverbSpec(IRlength=IRlength,
                                    room_dimensions=room_dimensions,
                                    t60=t60,
                                    reflectivity=None,
                                    source_type=source_type,
                                    microphone_type=microphone_type)
        else:
            reverb = SmirReverbSpec(IRlength=IRlength,
                                    room_dimensions=room_dimensions,
                                    t60=None,
                                    reflectivity=reflectivity,
                                    source_type=source_type,
                                    microphone_type=microphone_type)

        # Add event to foreground specification
        self.reverb_spec = reverb

        return


    def add_recorded_reverb(self, name):
        '''
        TODO
        :param reverb_name:
        :return:
        '''

        # SAFETY_CHECKS
        _validate_s3a_reverb_spec(name)

        # Create reverb spec
        self.reverb_spec = S3aReverbSpec(name=name)

        return

    def _instantiate_event(self, event, event_idx,
                           isbackground=False,
                           allow_repeated_source=True,
                           used_source_files=[],
                           disable_instantiation_warnings=False):
        '''
        Instantiate an event specification.

        Given an event specification containing distribution tuples,
        instantiate the event, i.e. samples values for the source_file,
        source_time, event_time, event_duration and snr from their respective
        distribution tuples, and return the sampled values in as a new event
        specification.

        Parameters
        ----------
        event : EventSpec
            Event specification containing distribution tuples.
        isbackground : bool
            Flag indicating whether the event to instantiate is a background
            event or not (False implies it is a foreground event).
        allow_repeated_source : bool
            When True (default) any source file can
            be used, including a source file that has already been used for
            another event. When False, only a source file that is not already
            in ``used_source_files`` can be selected.
        used_source_files : list
            List of full paths to source files that have already been used in
            the current soundscape instantiation. The source file selected for
            instantiating the event will be appended to this list unless its
            already in it.
        disable_instantiation_warnings : bool
            When True (default is False), warnings stemming from event
            instantiation (primarily about automatic duration adjustments) are
            disabled. Not recommended other than for testing purposes.

        Returns
        -------
        instantiated_event : EventSpec
            Event specification containing values sampled from the distribution
            tuples of the input event specification.

        Raises
        ------
        AmbiScaperError
            If allow_repeated_source is False and there is no valid source file
            to select.

        '''
        # set paths depending on whether its a foreground/background
        # event
        if isbackground:
            file_path = self.bg_path
            event_id = _generate_event_id_from_idx(event_idx,'background')
        else:
            file_path = self.fg_path
            event_id = _generate_event_id_from_idx(event_idx, 'foreground')


        # determine source file
        if event.source_file[0] == "choose" and not event.source_file[1]:
            source_files = _get_sorted_files(file_path)
            source_file_tuple = list(event.source_file)
            source_file_tuple[1] = source_files
            source_file_tuple = tuple(source_file_tuple)
        else:
            source_file_tuple = event.source_file

        source_file = _get_value_from_dist(source_file_tuple)

        # Make sure we can use this source file
        if (not allow_repeated_source) and (source_file in used_source_files):
            source_files = _get_sorted_files(file_path)
            if (len(source_files) == len(used_source_files) or
                        source_file_tuple[0] == "const"):
                raise AmbiScaperError(
                    "Cannot instantiate event {:s}: all available source "
                    "files have already been used")
            else:
                while source_file in used_source_files:
                    source_file = _get_value_from_dist(source_file_tuple)

        # Update the used source files list
        if source_file not in used_source_files:
            used_source_files.append(source_file)

        # Get the duration of the source audio file
        source_duration = sox.file_info.duration(source_file)

        # Determine event duration
        # For background events the duration is fixed to self.duration
        # (which must be > 0), but for foreground events it could
        # potentially be non-positive, hence the loop.
        event_duration = -np.Inf
        while event_duration <= 0:
            event_duration = _get_value_from_dist(event.event_duration)

        # Check if chosen event duration is longer than the duration of the
        # selected source file, if so adjust the event duration.
        if (event_duration > source_duration):
            old_duration = event_duration  # for warning
            event_duration = source_duration
            if not disable_instantiation_warnings:
                warnings.warn(
                    "Event duration ({:.2f}) is greater that source "
                    "duration ({:.2f}), changing to {:.2f}".format(
                        old_duration, source_duration, event_duration),
                    AmbiScaperWarning)

        # Get the event azimuth
        event_azimuth = _get_value_from_dist(event.event_azimuth)

        # Get the event elevation
        event_elevation = _get_value_from_dist(event.event_elevation)

        # Get the event spread
        event_spread = _get_value_from_dist(event.event_spread)

        # Get time stretch value
        if event.time_stretch is None:
            time_stretch = None
            event_duration_stretched = event_duration
        else:
            time_stretch = -np.Inf
            while time_stretch <= 0:
                time_stretch = _get_value_from_dist(event.time_stretch)
            # compute duration after stretching
            event_duration_stretched = event_duration * time_stretch

        # If the event duration is longer than the soundscape we can trim it
        # without losing validity (since the event will end when the soundscape
        # ends).
        if time_stretch is None:
            if (event_duration > self.duration):
                old_duration = event_duration  # for warning
                event_duration = self.duration
                if not disable_instantiation_warnings:
                    warnings.warn(
                        "Event duration ({:.2f}) is greater than the "
                        "soundscape duration ({:.2f}), changing to "
                        "{:.2f}".format(
                            old_duration, self.duration, self.duration),
                        AmbiScaperWarning)
        else:
            if (event_duration_stretched > self.duration):
                old_duration = event_duration  # for warning
                event_duration = self.duration / float(time_stretch)
                if not disable_instantiation_warnings:
                    warnings.warn(
                        "Event duration ({:.2f}) with stretch factor "
                        "{:.2f} gives {:.2f} which is greater than the "
                        "soundscape duration ({:.2f}), changing to "
                        "{:.2f}".format(
                            old_duration, time_stretch,
                            event_duration_stretched, self.duration,
                            event_duration),
                        AmbiScaperWarning)

        # determine source time
        source_time = -np.Inf
        while source_time < 0:
            source_time = _get_value_from_dist(event.source_time)

        # Make sure source time + event duration is not greater than the
        # source duration, if it is, adjust the source time (i.e. duration
        # takes precedences over start time).
        if source_time + event_duration > source_duration:
            old_source_time = source_time
            source_time = source_duration - event_duration
            if not disable_instantiation_warnings:
                warnings.warn(
                    'Source time ({:.2f}) is too great given event '
                    'duration ({:.2f}) and source duration ({:.2f}), changed '
                    'to {:.2f}.'.format(
                        old_source_time, event_duration,
                        source_duration, source_time),
                    AmbiScaperWarning)

        # determine event time
        # for background events the event time is fixed to 0, but for
        # foreground events it's not.
        event_time = -np.Inf
        while event_time < 0:
            event_time = _get_value_from_dist(event.event_time)

        # Make sure the selected event time + event duration are is not greater
        # than the total duration of the soundscape, if it is adjust the event
        # time. This means event duration takes precedence over the event
        # start time.
        if time_stretch is None:
            if event_time + event_duration > self.duration:
                old_event_time = event_time
                event_time = self.duration - event_duration
                if not disable_instantiation_warnings:
                    warnings.warn(
                        'Event time ({:.2f}) is too great given event '
                        'duration ({:.2f}) and soundscape duration ({:.2f}), '
                        'changed to {:.2f}.'.format(
                            old_event_time, event_duration,
                            self.duration, event_time),
                        AmbiScaperWarning)
        else:
            if event_time + event_duration_stretched > self.duration:
                old_event_time = event_time
                event_time = self.duration - event_duration_stretched
                if not disable_instantiation_warnings:
                    warnings.warn(
                        'Event time ({:.2f}) is too great given '
                        'stretched event duration ({:.2f}) and soundscape '
                        'duration ({:.2f}), changed to {:.2f}.'.format(
                            old_event_time, event_duration_stretched,
                            self.duration, event_time),
                        AmbiScaperWarning)

        # determine snr
        snr = _get_value_from_dist(event.snr)

        # get role (which can only take "foreground" or "background" and
        # is set internally, not by the user).
        role = event.role

        # determine pitch_shift
        if event.pitch_shift is not None:
            pitch_shift = _get_value_from_dist(event.pitch_shift)
        else:
            pitch_shift = None

        # pack up instantiated values in an EventSpec
        instantiated_event = EventSpec(event_id=event_id,
                                       source_file=source_file,
                                       source_time=source_time,
                                       event_time=event_time,
                                       event_duration=event_duration,
                                       event_azimuth=event_azimuth,
                                       event_elevation=event_elevation,
                                       event_spread=event_spread,
                                       snr=snr,
                                       role=role,
                                       pitch_shift=pitch_shift,
                                       time_stretch=time_stretch)
        # Return
        return instantiated_event

    def _instantiate_reverb(self):

        if type (self.reverb_spec) is SmirReverbSpec:
            return self._instantiate_smir_reverb()
        elif type(self.reverb_spec) is S3aReverbSpec:
            return self._instantiate_s3a_reverb()
        else:
            raise AmbiScaperError(
                'Unknown reverb type')


    def _instantiate_smir_reverb(self,
                           disable_instantiation_warnings=False):
        '''

        :param disable_instantiation_warnings:
        :return:
        '''

        reverb = self.reverb_spec

        # We cast manually everything to float, so Matlab will understand it

        # Get IR length
        IRlength = float(_get_value_from_dist(reverb.IRlength))

        # Get room dimensions
        room_dimensions = [float(dim) for dim in _get_value_from_dist(reverb.room_dimensions)]

        # Get t60
        if reverb.t60 is not None:
            t60 = float(_get_value_from_dist(reverb.t60))
            reflectivity = None
        # or get wall_reflectivity
        else:
            t60 = None
            reflectivity = [float(r) for r in _get_value_from_dist(reverb.reflectivity)]

        # Get source type
        source_type = _get_value_from_dist(reverb.source_type)

        # Get microphone type
        microphone_type = _get_value_from_dist(reverb.microphone_type)

        # pack up instantiated values in an SmirReverbSpec
        # NOTE: we set up as None the non-initialized value
        # For that we must use the jams methods in strict=False mode!

        if reverb.t60 is not None:
            instantiated_reverb = SmirReverbSpec(IRlength=IRlength,
                                    room_dimensions=room_dimensions,
                                    t60=t60,
                                    reflectivity=None,
                                    source_type=source_type,
                                    microphone_type=microphone_type)
        else:
            instantiated_reverb = SmirReverbSpec(IRlength=IRlength,
                                    room_dimensions=room_dimensions,
                                    t60=None,
                                    reflectivity=reflectivity,
                                    source_type=source_type,
                                    microphone_type=microphone_type)
        # Return
        return instantiated_reverb


    def _instantiate_s3a_reverb(self,
                                disable_instantiation_warnings=False):

        name = self.reverb_spec.name

        # If 'choose' and list is empty, then choose from all available IRs
        if name[0] == "choose" and not name[1]:
            name_tuple = list(name)
            name_tuple[1] = retrieve_available_recorded_IRs()
            name_tuple = tuple(name_tuple)
        else:
            name_tuple = name
        name = _get_value_from_dist(name_tuple)

        return S3aReverbSpec(name=name)

    def _instantiate(self,
                     allow_repeated_source=True,
                     disable_instantiation_warnings=False):
        '''
        Instantiate a specific soundscape in JAMS format based on the current
        specification.

        Any non-deterministic event values (i.e. distribution tuples) will be
        sampled randomly from based on the distribution parameters.

        Parameters
        ----------
        allow_repeated_source : bool
            When True (default) the same source file can be used more than once
            in a soundscape instantiation. When False every source file can
            only be used once.

        disable_instantiation_warnings : bool
            When True (default is False), warnings stemming from event
            instantiation (primarily about automatic duration adjustments) are
            disabled. Not recommended other than for testing purposes.

        Returns
        -------
        jam : JAMS object
            A JAMS object containing a sound_event annotation representing the
            instantiated soundscape.

        See Also
        --------
        AmbiScaper.generate

        '''
        jam = jams.JAMS()

        ############### andres

        # Let's instanciate the reverb before the sound events.
        # Since the recorded reverbs impose a limitation on the source positions,
        # we will need this information beforehand.


        if self.reverb_spec:

            # INSTANTIATE REVERB VALUES
            instantiated_reverb_spec = self._instantiate_reverb()

            # LIMIT AMBISONICS ORDER
            # The Ambisonic IRs might present a limitation on the ambisonics order
            # (lack of higher order recordings, or not enough simulated capsules)
            # We compute and store here the maximum order allowed,
            # and downgrade it if necessary
            max_ambi_order =  get_max_ambi_order_from_reverb_config(instantiated_reverb_spec)

            if max_ambi_order < self.ambisonics_order:
                warnings.warn(
                    'User-defined Ambisonics order L=' + str(self.ambisonics_order) +
                    ' is higher than the maximum order allowed by the reverb spec. ' +
                    'Downgrading to ' + str(max_ambi_order),
                    AmbiScaperWarning)
                self.ambisonics_order = max_ambi_order


            if isinstance(instantiated_reverb_spec,SmirReverbSpec):

                ann_reverb = jams.Annotation(namespace='ambiscaper_smir_reverb')

                # Add specs and other info to sandbox
                # TODO: this way is more concise, because it specifies each tuple name and values
                # TODO: But, it is not compatible with the sound_event Sandbox, which is not labelled
                # TODO: What should we do?
                ann_reverb.sandbox.ambiscaper = jams.Sandbox(

                    # all this?
                    # IRlength = self.reverb_spec.IRlength,
                    # room_dimensions = self.reverb_spec.room_dimensions,
                    # t60 = self.reverb_spec.t60,
                    # reflectivity = self.reverb_spec.reflectivity,
                    # source_type = self.reverb_spec.source_type,
                    # microphone_type = self.reverb_spec.microphone_type,
                    # microphone_sphere_type = SMIR_SUPPORTED_VIRTUAL_MICS[self.reverb_spec.microphone_type[1]]["sph_type"],
                    # microphone_sphere_radius = SMIR_SUPPORTED_VIRTUAL_MICS[self.reverb_spec.microphone_type[1]]["sph_radius"],
                    # microphone_capsule_coordinates = SMIR_SUPPORTED_VIRTUAL_MICS[self.reverb_spec.microphone_type[1]]["mic"],
                    # add also default smir parameters
                    reverb_spec = self.reverb_spec,
                    microphone_sphere_type = SMIR_SUPPORTED_VIRTUAL_MICS[instantiated_reverb_spec.microphone_type]["sph_type"],
                    microphone_sphere_radius = SMIR_SUPPORTED_VIRTUAL_MICS[instantiated_reverb_spec.microphone_type]["sph_radius"],
                    microphone_capsule_coordinates = SMIR_SUPPORTED_VIRTUAL_MICS[instantiated_reverb_spec.microphone_type]["capsule_position_sph"],
                    sample_rate = self.sr,
                    sound_speed = SMIR_SOUND_SPEED,
                    num_harmonics = SMIR_NUM_HARMONICS,
                    oversampling = SMIR_OVERSAMPLING_FACTOR,
                    sph_location = get_receiver_position(instantiated_reverb_spec.room_dimensions),
                    hp = SMIR_HIGH_PASS_FILTER,
                    reflection_order= SMIR_REFLECTION_ORDER,
                    reflection_coef_ang_dep = SMIR_REFLECTION_COEF_ANGLE_DEPENDENCY,
                    # [radius, azimuth, elevation]
                    # todo: is it needed?
                    # source_positions_sph = [[SMIR_DEFAULT_SOURCE_RADIUS,pos[0],pos[1]] for pos in fg_source_positions],
            )

            elif isinstance(instantiated_reverb_spec, S3aReverbSpec):

                ann_reverb = jams.Annotation(namespace='ambiscaper_recorded_reverb')

                # TODO: should we add some info to sandbox??

                # Retrieve loudspeaker positions
                imposed_source_positions = retrieve_RIR_positions(instantiated_reverb_spec.name)

                # Since we cannot modify directly an EventSpec (todo: why?)
                # we will copy all valid args from each event, and create a new set of events
                # which will be attached to the fg_spec list
                imposed_fg_spec = []
                self.chosen_IR_indices = []

                for e in self.fg_spec:
                    # For the moment, just choose random on the imposed positions for each event
                    # TODO: do we want
                    random_index = random.randint(0, len(imposed_source_positions) - 1)
                    random_position = imposed_source_positions[random_index]
                    imposed_azimuth = ('const', random_position[0])
                    imposed_elevation = ('const', random_position[1])
                    imposed_spread = ('const', 0.0)

                    # Store the random indinces, so later in the generate_audio method we can
                    # easily retrieve the associated IRs
                    # Achtung! indices start at 0, but audio files start at 1...
                    self.chosen_IR_indices.append(random_index)

                    # Create a new event copying the other relevant informationo
                    imposed_fg_spec.append(EventSpec(event_id=e.event_id,
                                                     source_file=e.source_file,
                                                     source_time=e.source_time,
                                                     event_time=e.event_time,
                                                     event_duration=e.event_duration,
                                                     event_azimuth=imposed_azimuth,  # changed!
                                                     event_elevation=imposed_elevation,  # changed!
                                                     event_spread=imposed_spread,  # changed!
                                                     snr=e.snr,
                                                     role=e.role,
                                                     pitch_shift=e.pitch_shift,
                                                     time_stretch=e.time_stretch))

                # Actually substitute the old events for the new imposed ones
                self.fg_spec = []
                [self.fg_spec.append(e) for e in imposed_fg_spec]


            ann_reverb.append(time=0.0,   # TODO: does it have any meaning for a reverb?
                       duration=0.0,      # TODO: does it have any meaning for a reverb?
                       value=instantiated_reverb_spec._asdict(),
                       confidence=1.0)

            jam.annotations.append(ann_reverb)


        #############################################

        # INSTANTIATE BACKGROUND AND FOREGROUND EVENTS AND ADD TO ANNOTATION
        # NOTE: logic for instantiating bg and fg events is NOT the same.

        ann = jams.Annotation(namespace='ambiscaper_sound_event')

        # Set annotation duration (might be changed later due to cropping)
        ann.duration = self.duration

        # Add background sounds
        bg_source_files = []
        for event_idx, event in enumerate(self.bg_spec):
            value = self._instantiate_event(
                event,
                event_idx,
                isbackground=True,
                allow_repeated_source=allow_repeated_source,
                used_source_files=bg_source_files,
                disable_instantiation_warnings=disable_instantiation_warnings)

            # Note: add_background doesn't allow to set a time_stretch, i.e.
            # it's hardcoded to time_stretch=None, so we don't need to check
            # if value.time_stretch is not None, since it always will be.
            ann.append(time=value.event_time,
                       duration=value.event_duration,
                       value=value._asdict(),
                       confidence=1.0)

        # Keep them for the reverb spec...
        fg_source_positions = []

        # Add foreground events
        fg_source_files = []
        for event_idx, event in enumerate(self.fg_spec):
            value = self._instantiate_event(
                event,
                event_idx,
                isbackground=False,
                allow_repeated_source=allow_repeated_source,
                used_source_files=fg_source_files,
                disable_instantiation_warnings=disable_instantiation_warnings)

            # Retrieve source position
            fg_source_positions.append([value.event_azimuth,value.event_elevation])

            if value.time_stretch is not None:
                event_duration_stretched = (
                    value.event_duration * value.time_stretch)
            else:
                event_duration_stretched = value.event_duration

            ann.append(time=value.event_time,
                       duration=event_duration_stretched,
                       value=value._asdict(),
                       confidence=1.0)


        # Compute max polyphony
        poly = max_polyphony(ann)

        # Compute the number of foreground events
        n_events = len(self.fg_spec)

        # Compute gini
        gini = polyphony_gini(ann)

        # Add specs and other info to sandbox
        ann.sandbox.ambiscaper = jams.Sandbox(
            duration=self.duration,
            fg_path=self.fg_path,
            bg_path=self.bg_path,
            fg_spec=self.fg_spec,
            bg_spec=self.bg_spec,
            ref_db=self.ref_db,
            ambisonics_order=self.ambisonics_order,
            ambisonics_spread_slope=self.ambisonics_spread_slope,
            fade_in_len=self.fade_in_len,
            fade_out_len=self.fade_out_len,
            n_events=n_events,
            polyphony_max=poly,
            polyphony_gini=gini,
            allow_repeated_source=allow_repeated_source)
        # Add annotation to jams
        jam.annotations.append(ann)

        # Set jam metadata
        jam.file_metadata.duration = ann.duration


        # Return
        return jam

    def _mono_downmix(self, file_path):
        '''
        Take the path to an audio file and produce a tmp file downmixed to mono,
        and with system's sample rate

        Parameters
        ----------
        file_path : str
            Path to the audio file to be downmixed

        Returns
        ------
        downmix_tmpfile: tmp file
            A reference to the created  tmpfile

        Raises
        TODO
        ------
        AmbiScaperError
            If annotation is not of the sound_event namespace.

        '''

        # Instanciate sox transformer to perform sr and channel conversion
        downmix_transformer = sox.Transformer()
        downmix_transformer.convert(samplerate=self.sr,
                                    n_channels=1,
                                    bitdepth=None)

        # Create removable tmp file to store it. Don't store on the valid tmpfiles list
        downmix_tmpfile = tempfile.NamedTemporaryFile(
            suffix='.wav',
            delete=False)

        # Actual rendering
        downmix_transformer.build(file_path, downmix_tmpfile.name)
        return downmix_tmpfile


    def _compute_smir_IRs(self,e,instantiated_reverb_values):
        '''
        # TODO: calling matlab...
        :return:
        '''

        # Clear workspace, just in case
        self.matlab.eval('clear')

        # Follow parameter definition as stated in run_smir_generator.m
        # Copy all parameters into the matlab workspace, and call the script
        # which actually calls the smir_generator method.
        # Just make sure that all values are passed as floats

        # Sample Rate of the session
        self.matlab.put('procFs', float(self.sr))
        # Default speed of sound
        self.matlab.put('c', float(SMIR_SOUND_SPEED))
        # Buffer size given by the user
        self.matlab.put('nsample', float(instantiated_reverb_values['IRlength']))

        # Default number of harmonics
        # TODO? HOW IS THIS RELATED TO THE AMBISONICS ORDER?
        self.matlab.put('N_harm', float(SMIR_NUM_HARMONICS))
        # Default oversampling (no oversamplig)
        self.matlab.put('K', float(SMIR_OVERSAMPLING_FACTOR))

        # Room dimensions given by the user (with float casting)
        self.matlab.put('L', instantiated_reverb_values['room_dimensions'])
        # Receiver will be at the middle of the room
        # TODO: make it configurable??
        self.matlab.put('sphLocation', get_receiver_position(instantiated_reverb_values['room_dimensions']))
        # Source location will be given by the specific instance
        azi = e.value['event_azimuth'],
        ele = e.value['event_elevation']
        self.matlab.put('s', (spherical_to_cartesian([float(e.value['event_azimuth']),
                                                      float(e.value['event_elevation']),
                                                      float(SMIR_DEFAULT_SOURCE_RADIUS)])))

        # Default no High Pass Filter
        self.matlab.put('HP', float(SMIR_HIGH_PASS_FILTER))

        # Source directivity type given by the user
        self.matlab.put('src_type', instantiated_reverb_values['source_type'])
        # Source angle pointing to the receiver (default behavior by ommision)
        # src_ang

        # Reflection order by default
        self.matlab.put('order', float(SMIR_REFLECTION_ORDER))
        # Not really sure what's this "room/angle dependent coeff, but let's keep it off
        self.matlab.put('refl_coeff_ang_dep', float(SMIR_REFLECTION_COEF_ANGLE_DEPENDENCY))

        # Beta given by the user.
        # It might be either a float (T_60 in seconds)
        # or wall reflectivity in list of len(6)
        if instantiated_reverb_values['t60'] is None:
            # reflectivity
            self.matlab.put('beta', instantiated_reverb_values['reflectivity'])
        else:
            # t60
            self.matlab.put('beta', instantiated_reverb_values['t60'])

        # Sph_type, sph_radius, mic positions, given by the microphone type
        mic = instantiated_reverb_values['microphone_type']
        self.matlab.put('sphType',
                        SMIR_SUPPORTED_VIRTUAL_MICS[mic]["sph_type"])
        self.matlab.put('sphRadius',
                        SMIR_SUPPORTED_VIRTUAL_MICS[mic]["sph_radius"])
        self.matlab.put('mic',
                        SMIR_SUPPORTED_VIRTUAL_MICS[mic]["capsule_position_sph"])

        # Run the algorithm
        self.matlab.eval('run_smir_generator_from_python')
        # Get the data back
        h = self.matlab.get('h')

        return h


    def _generate_ambisonics_reverb_from_smir_spec(self,destination_path,event,reverb_annotation):
        '''
        #TODO
        '''

        # Retrieve instanciated values from the previously computed reverb annotation
        instantiated_reverb_values = reverb_annotation.data.value[0]

        # Result of the method is the actual multichannel IRs
        # as recorded by the virtual microphones (A-Format if you want)
        # mic_IRs is a matrix of shape (num_capsules, num_samples)
        mic_IRs = self._compute_smir_IRs(event,instantiated_reverb_values)

        # We need to convert them to ambisonics, i.e., perform ambisonics encoding on them
        # based on the capsule positions
        mic = instantiated_reverb_values['microphone_type']
        ambi_coefs = []
        for mic_pos in SMIR_SUPPORTED_VIRTUAL_MICS[mic]["capsule_position_sph"]:
            azi = mic_pos[0]
            ele = mic_pos[1]
            # ambi_coefs is a matrix of shape (num_capsules, num_ambisonics_channels)
            ambi_coefs.append(get_ambisonics_coefs(azi,ele,self.ambisonics_order))


        # Just for testing purposes
        # sf.write("/Volumes/Dinge/ambiscaper/generated/soundscape0/source/mic_IR.wav",
        #          np.transpose(mic_IRs),
        #          self.sr,
        #          subtype='PCM_16')

        # Then, we need as a result a matrix of shape (num_ambisonics_channels, num_samples)
        # which is in fact the deinterleaved form of the ambisonics IRs
        ambi_IRs = np.dot(np.transpose(np.array(ambi_coefs)),mic_IRs)

        # Write the resulting IRs into the given destination path
        sf.write(destination_path, np.transpose(ambi_IRs), self.sr, subtype='PCM_16')
        return


    def _generate_audio(self, destination_path, audio_filename, annotation_array,
                        disable_sox_warnings=True):
        '''
        Generate audio based on a sound_event annotation and save to disk.

        Parameters
        ----------
        destination_path: str
            Path to the folder where to produce results
        audio_filename : str
            File name of the audio soundscape, stored at destination_path
        TODO///
        ann : jams.Annotation
            Annotation of the sound_event namespace.
        ////
        reverb : float or None
            Amount of reverb to apply to the generated soundscape between 0
            (no reverberation) and 1 (maximum reverberation). Use None
            (default) to prevent the soundscape from going through the reverb
            module at all.
        disable_sox_warnings : bool
            When True (default), warnings from the pysox module are suppressed
            unless their level is ``'CRITICAL'``.

        Raises
        ------
        AmbiScaperError
            If annotation is not of the sound_event namespace.

        See Also
        --------
        AmbiScaper.generate

        '''

        # Ignore pandas deprecation warning
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            annotation_event = annotation_array.search(namespace='ambiscaper_sound_event')[0]

            # Set annotation_reverb to empty valuye
            annotation_reverb = None

            # Check if there is annotation reverb
            for namespace in ['ambiscaper_smir_reverb','ambiscaper_recorded_reverb']:
                ann = annotation_array.search(namespace=namespace)
                if ann:
                    annotation_reverb = ann[0]

            if annotation_reverb is None and self.reverb_spec: # check for empty list
                raise AmbiScaperError(
                    'Error: no annotation reverb found, but reverb spec defined'
                )

        # Error: no events!
        if not annotation_event:
            raise AmbiScaperError(
                'Annotation namespaces not correct!')


        # disable sox warnings
        if disable_sox_warnings:
            temp_logging_level = 'CRITICAL'  # only critical messages please
        else:
            temp_logging_level = logging.getLogger().level

        with _set_temp_logging_level(temp_logging_level):

            # We maintain three lists for handling convenience audio files
            # :downmix_tmpfiles: stores the downmixed and sr-adjusted versions
            #   for each sound. Not really needed afterwards, so they get deleted
            # :preprocessed_files: the previous mono signal, with some transformations
            #   (trim, gain correction, and pitch shift and time strecth in the case of foreground)
            #   The actual sound content of these files will be inserted in the general
            #   ambisonics scene, so that we need to keep them to be able to validate separation
            # :processed_tmpfiles: the preprocessed files with zero-padding to adjust start/end
            #   and ambisonics encoding. Only needed until forming the ambisonics soundscene
            downmix_tmpfiles = []
            preprocessed_files = []
            processed_tmpfiles = []

            # Create the separated source subfolder
            # Again, if already exists, will be overrided
            source_folder_name = 'source'
            destination_source_path = os.path.join(destination_path, source_folder_name)
            try:
                os.mkdir(destination_source_path)
            except OSError as err:
                if err.errno != 17:  # folder exists
                    raise
                    # If we arrived here because the folder already existed,
                    # don't warn again, since the parent folder also existed
                    # and the user already received a warning


            # Define functions to handle the type of event
            def is_background(event):
                return e.value['role'] == 'background'

            def is_foreground(event):
                return e.value['role'] == 'foreground'

            # Delete processed_tmpfiles only at the end of the method's lifetime
            # with _close_temp_files(processed_tmpfiles):

            # Iterate over all events specified in the event annotation
            # fg_event_idx = -1 TODO
            for event in annotation_event.data.iterrows():

                # first item is index, second is event dictionary
                e = event[1]

                audio_event_filename = e.value['event_id']+'.wav'
                ir_filename = 'ir_'+audio_event_filename


                # First of all, ensure pre-downmix to mono
                downmix_tmpfiles.append(
                    self._mono_downmix(e.value['source_file']))

                # Create transformer
                fx_transformer = sox.Transformer()
                # Ensure consistent sampling rate
                fx_transformer.convert(samplerate=self.sr,
                                       n_channels=None,  # mono
                                       bitdepth=None)

                # Trim
                fx_transformer.trim(e.value['source_time'],
                                    e.value['source_time'] +
                                    e.value['event_duration'])

                if is_foreground(e):
                    # Pitch shift
                    if e.value['pitch_shift'] is not None:
                        fx_transformer.pitch(e.value['pitch_shift'])

                    # Time stretch
                    if e.value['time_stretch'] is not None:
                        fx_transformer.tempo(1.0 / float(e.value['time_stretch']))

                        # Apply very short fade in and out
                        # (avoid unnatural sound onsets/offsets)
                        fx_transformer.fade(fade_in_len=self.fade_in_len,
                                            fade_out_len=self.fade_out_len)

                # Normalize to specified SNR with respect to
                # self.ref_db (from downmixed version)
                lufs = get_integrated_lufs(downmix_tmpfiles[-1].name)
                if is_foreground(e):
                    gain = self.ref_db + e.value['snr'] - lufs
                elif is_background(e):
                    gain = self.ref_db - lufs
                else:
                    raise AmbiScaperError(
                        'Unsupported event role: {:s}'.format(
                            e.value['role']))
                fx_transformer.gain(gain_db=gain, normalize=False)

                # Here we got the final mono file with transformations
                # but before time padding and ambisonics transformation
                # So this is the signal we should save for the separation validation
                # (which can be found in this loop as "preprocessed_files[-1]")

                preprocessed_files.append(
                    os.path.join(destination_source_path, audio_event_filename))

                # Build
                fx_transformer.build(input_filepath=downmix_tmpfiles[-1].name,
                                     output_filepath=preprocessed_files[-1],
                                     extra_args=None,
                                     return_output=False)

                # Create combiner
                # note: Combiner inhereits from transformer,
                # so we can still apply all audio transforms
                # note2: we cannot use a plain Transformer,
                # because volume controls are still not implemented
                # on the remix method
                fx_combiner = sox.Combiner()
                fx_combiner.convert(samplerate=self.sr,
                                    n_channels=self.num_channels,  # num_ambisonics_channels
                                    bitdepth=None)

                # Pad with silence before/after event to match the
                # soundscape duration
                if is_foreground(e):
                    prepad = e.value['event_time']
                    if e.value['time_stretch'] is None:
                        postpad = max(
                            0, self.duration - (e.value['event_time'] +
                                                e.value['event_duration']))
                    else:
                        postpad = max(
                            0, self.duration - (e.value['event_time'] +
                                                e.value['event_duration'] *
                                                e.value['time_stretch']))
                    fx_combiner.pad(prepad, postpad)

                # Ambisonics
                #
                # Two main methods of operation here:
                # 1.)   If there is no reverb, then compute the ambisonics encoding for each source
                #       and combine them together.
                #       That should be equivalent to convolving with deltas,
                #       so maybe in the future we implement it in that way to make it more consistent
                # 2.)   If there is reverb, then compute or retrieve the IRs according to the source positions,
                #       and then convolve them with the sources

                # If we DON'T have reverb...
                if not annotation_reverb:

                    if is_foreground(e):
                        # if foreground, apply both ambi coefs and spread
                        input_volumes = get_ambisonics_coefs(e.value['event_azimuth'],
                                                             e.value['event_elevation'],
                                                             self.ambisonics_order)
                        input_volumes *= get_ambisonics_spread_coefs(
                            e.value['event_spread'],
                            self.ambisonics_spread_slope,
                            self.ambisonics_order)
                    elif is_background(e):
                        # Apply just maximum spread (W gain is 1 in SN3D)
                        input_volumes = get_ambisonics_spread_coefs(
                            1.0,
                            self.ambisonics_spread_slope,
                            self.ambisonics_order)

                    # Prepare tmp file for output
                    processed_tmpfiles.append(
                        tempfile.NamedTemporaryFile(
                            suffix='.wav', delete=False))

                    # Build by passing a list of duplicated downmixed files
                    # and 'merging' it with targed ambisonics gains and spreads (one for each channel)
                    fx_combiner.build(input_filepath_list=[preprocessed_files[-1] for _ in range(self.num_channels)],
                                      output_filepath=processed_tmpfiles[-1].name,
                                      combine_type='merge',
                                      input_volumes=input_volumes.tolist())


                # There is ambisonics reverb:
                # Create or find the desired IR, and then convolve with the source
                else:
                    if not is_foreground(e):
                        # Just apply reverb to foreground sounds
                        return

                     # Check reverb type and get IR

                    #########################
                    #########################
                    #########################

                    # for r in annotation_reverb.data.iterrows():
                    #     print(r[1].value['name'])

                    if annotation_reverb.namespace is 'ambiscaper_smir_reverb':
                    # if type(self.reverb_spec) is SmirReverbSpec:
                        ### Model IR through smir_generator in matlab ###

                        # Save IRs as irX.wav in the same source folder
                        used_filter_path = os.path.join(destination_source_path, ir_filename)
                        self._generate_ambisonics_reverb_from_smir_spec(used_filter_path,e,annotation_reverb)

                    elif annotation_reverb.namespace is 'ambiscaper_recorded_reverb':
                        # Get the IRs associated to the source position
                        # They are stored at the chosen_IR_indices list
                        # Watch out with the indices (wav files numbering starting at 1)

                        # TODO: implement that in a more elegant way
                        reverb_name = annotation_reverb.data.value[0]['name']


                        # Construct the filter name given the speaker index:
                        # In each event iteration we selected a different speaker position
                        # since event_id contains a numeration of the events,
                        # we can retrieve the index from there

                        event_idx = _get_event_idx_from_id(e.value['event_id'],'foreground')

                        # FILTER NUMERATION STARTS WITH 1!!
                        ir_idx = self.chosen_IR_indices[event_idx] + 1

                        # ir_irx holds the index of the ir to be used with the actual source

                        used_filter_name = S3A_FILTER_NAME + str(ir_idx) + S3A_FILTER_EXTENSION
                        used_filter_path = os.path.join(generate_RIR_path(reverb_name), used_filter_name)

                        # Create a symlink to the used filter on the source folder
                        # We could just copy the filter there for consistency,
                        # but that would increase too much the output size
                        # ACHTUNG!!! os.symlink is only defined for Unix,
                        # so this line will probably break in Windows
                        # TODO: handle Windows compatibility, test in Linux
                        try:
                            symlink_path = os.path.join(destination_source_path, ir_filename)
                            os.symlink(used_filter_path, symlink_path)
                        except OSError as err:
                            if err.errno == 17:  # folder exists
                                warnings.warn(
                                    'Could not create symlink: file exists: ' + symlink_path
                                )
                            else:
                                raise


                    # In both reverb cases, at this point we have the IR at the location pointed by used_filter_path
                    # So we just convolve it with the source and save the result

                    # Open the filter
                    # filter_data is deinterleaved. e.g. channel 0 is filter_data[:, 0], etc
                    # TODO: check sr and change it in case
                    filter_data, filter_sample_rate = sf.read(used_filter_path)

                    # Ensure that num channels is what it should be according to ambisonics order..
                    # TODO!
                    num_channels = np.shape(filter_data)[1]

                    # The S3A filters are in fuma, so perform rescaling and channel reordering...
                    if annotation_reverb.namespace is 'ambiscaper_recorded_reverb':
                        ordered_filter_data = change_channel_ordering_fuma_2_acn(filter_data)
                        normalized_filter_data = change_normalization_fuma_2_sn3d(ordered_filter_data)
                        filter_data = normalized_filter_data

                    # Open the preprocessed file
                    # TODO: check sr of file and filter...
                    file_data, file_sample_rate = sf.read(preprocessed_files[-1])

                    # fftconvolve will try to convolve the signals in every dimension
                    # i.e., if we have two files with 4 channels, the result will have 7 channel
                    # Obviously that's not what we want, so the provisional workaround
                    # is to convolve each filter channel individually,
                    # and then put all them together when wav rendering
                    output_signal_list = []
                    for i in range(num_channels):
                        output_signal_list.append(scipy.signal.fftconvolve(file_data, filter_data[:, i]))

                    output_signal = np.transpose(np.array(output_signal_list))

                    # The convolved signal is already in ambisonics format
                    # What we can do now is to process it as a wavfile
                    # and store it with the processed_tmpfiles
                    # So we reuse the code for the anechoic case

                    # Prepare tmp file for output
                    processed_tmpfiles.append(
                        tempfile.NamedTemporaryFile(
                            suffix='.wav', delete=False))

                    # Change here the subtype for other format types
                    sf.write(processed_tmpfiles[-1].name, output_signal, self.sr, subtype='PCM_16')

            # Finally combine all the files and optionally apply reverb
            # If we have more than one tempfile (i.e.g background + at
            # least one foreground event, we need a combiner. If there's
            # only the background track, then we need a transformer!
            if len(processed_tmpfiles) == 0:
                warnings.warn(
                    "No events to synthesize (silent soundscape), no audio "
                    "saved to disk.", AmbiScaperWarning)
            elif len(processed_tmpfiles) == 1:
                # Just one file (bg or fg): just a transformer is fine
                final_transformer = sox.Transformer()
                # if reverb is not None:
                #     tfm.reverb(reverberance=reverb * 100)
                # TODO: do we want to normalize the final output?
                final_transformer.build(processed_tmpfiles[0].name,
                                        os.path.join(destination_path, audio_filename))
            else:
                # Combiner needed for more than one file
                final_combiner = sox.Combiner()
                # TODO: REVERB
                # if reverb is not None:
                #   tfm.reverb(reverberance=reverb * 100)
                final_combiner.build([t.name for t in processed_tmpfiles],
                                     os.path.join(destination_path, audio_filename),
                                     'mix')

            # Finally, clear all intermediate tmp files
            [os.remove(t.name) for t in downmix_tmpfiles]
            [os.remove(t.name) for t in processed_tmpfiles]


    def generate(self, destination_path,
                 allow_repeated_source=True,
                 disable_sox_warnings=True,
                 no_audio=False,
                 generate_txt=False,
                 txt_sep='\t',
                 disable_instantiation_warnings=False):


        # First, we will check reverb config.
        # Currently we support two types of ambisonics reverb:
        # - smir: matlab-simulated RIR (todo: link)
        # - s3a: recorded IR (todo: link)
        # In the case of recorded IRs, we are limited on the number of different
        # source locations.
        # Therefore, we must impose the source location limitation before the actual
        # value instanciation.
        # The audio generation process will also probably vary depending on the
        # reverb type selected...

        if (type(self.reverb_spec) is SmirReverbSpec):
            # Start Matlab Session
            self.matlab = matlab_wrapper.MatlabSession(matlab_root=MATLAB_ROOT)
            # Add smir code into the path
            self.matlab.eval('addpath ' + SMIR_FOLDER_PATH)


        # Create specific instance of a soundscape based on the spec
        jam = self._instantiate(
            allow_repeated_source=allow_repeated_source,
            disable_instantiation_warnings=disable_instantiation_warnings)

        # Implement the catch_warnings to avoid the timedelta deprecation message
        # (only with newest versions)
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            annotation_array = jam.annotations

        # Generate the output folder structure
        # We will use the same file name as the folder
        # for the audio and annotation files
        filename = os.path.split(destination_path)[-1]

        # Create the top folder
        # If it exists, the content will be overrided
        if os.path.exists(destination_path):
            warnings.warn('Destination path exists: ' + destination_path, AmbiScaperWarning)
        else:
            os.mkdir(destination_path)

        # Generate the audio and save to disk
        if not no_audio:
            self._generate_audio(destination_path,
                                 filename + '.wav',
                                 annotation_array,
                                 disable_sox_warnings=disable_sox_warnings)

        # Finally save JAMS to disk too
        # NOTE: using strict=False for allowing None values of not-implemented
        # values of smir_reverb (t60 or reflectivity)
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            jam.save(os.path.join(destination_path, filename + '.jams'),strict=False)

        # Optionally save to CSV as well
        if generate_txt:
            txt_path = os.path.join(destination_path, filename + '.txt')

            df = pd.DataFrame(columns=['onset', 'offset', 'name'])

            for idx, row in annotation_array.search(namespace='ambiscaper_sound_event')[0].data.iterrows():
                if row.value['role'] == 'foreground':
                    name = row.value['event_id']
                    newrow = ([row.time.total_seconds(),
                               row.time.total_seconds() +
                               row.duration.total_seconds(),
                               name])
                    df.loc[len(df)] = newrow

            # sort events by onset time
            df = df.sort_values('onset')
            df.reset_index(inplace=True, drop=True)
            df.to_csv(os.path.join(destination_path, txt_path),
                      index=False,
                      header=False,
                      sep=txt_sep)
